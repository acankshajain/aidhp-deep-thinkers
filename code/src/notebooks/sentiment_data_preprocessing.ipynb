{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the root folder relative to the current working directory\n",
    "root_folder = os.path.join(os.getcwd(), \"../data/redditFinance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 17100 entries, 1 to 20514\n",
      "Data columns (total 1 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Caption  17100 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 267.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "instagram_captions_df = pd.read_csv('/Users/acankshajain/ml-projects/UserBased/data/instaCaptions.csv')\n",
    "instagram_captions_df.drop(columns=['Image File', 'Sr No'], inplace=True)\n",
    "instagram_captions_df.dropna(inplace=True)\n",
    "print(instagram_captions_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 250 entries, 6090 to 1963\n",
      "Data columns (total 1 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Caption  250 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 3.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Randomly select 250 rows\n",
    "sampled_df = instagram_captions_df.sample(n=250, random_state=42)\n",
    "\n",
    "# Save the sampled DataFrame to a CSV file\n",
    "sampled_df.to_csv(\"final_instagram_captions.csv\", index=False)\n",
    "\n",
    "# Print information about the sampled DataFrame\n",
    "print(sampled_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed /Users/acankshajain/ml-projects/UserBased/sentimentAnalysis/../data/redditFinance/gme/submissions_reddit.csv\n",
      "Processed /Users/acankshajain/ml-projects/UserBased/sentimentAnalysis/../data/redditFinance/stockmarket/submissions_reddit.csv\n",
      "Processed /Users/acankshajain/ml-projects/UserBased/sentimentAnalysis/../data/redditFinance/options/submissions_reddit.csv\n",
      "Processed /Users/acankshajain/ml-projects/UserBased/sentimentAnalysis/../data/redditFinance/investing/submissions_reddit.csv\n",
      "Processed /Users/acankshajain/ml-projects/UserBased/sentimentAnalysis/../data/redditFinance/forex/submissions_reddit.csv\n",
      "Processed /Users/acankshajain/ml-projects/UserBased/sentimentAnalysis/../data/redditFinance/stocks/submissions_reddit.csv\n",
      "Processed /Users/acankshajain/ml-projects/UserBased/sentimentAnalysis/../data/redditFinance/robinhoodpennystocks/submissions_reddit.csv\n",
      "Processed /Users/acankshajain/ml-projects/UserBased/sentimentAnalysis/../data/redditFinance/financialindependence/submissions_reddit.csv\n",
      "Processed /Users/acankshajain/ml-projects/UserBased/sentimentAnalysis/../data/redditFinance/securityanalysis/submissions_reddit.csv\n",
      "Processed /Users/acankshajain/ml-projects/UserBased/sentimentAnalysis/../data/redditFinance/robinhood/submissions_reddit.csv\n",
      "Processed /Users/acankshajain/ml-projects/UserBased/sentimentAnalysis/../data/redditFinance/pennystocks/submissions_reddit.csv\n",
      "Processed /Users/acankshajain/ml-projects/UserBased/sentimentAnalysis/../data/redditFinance/finance/submissions_reddit.csv\n",
      "Processed /Users/acankshajain/ml-projects/UserBased/sentimentAnalysis/../data/redditFinance/wallstreetbets/submissions_reddit.csv\n",
      "Processed /Users/acankshajain/ml-projects/UserBased/sentimentAnalysis/../data/redditFinance/personalfinance/submissions_reddit.csv\n",
      "\n",
      "Final DataFrame with 1500797 rows:\n",
      "                                               title  upvote_ratio\n",
      "0                                 GME to the moon ðŸš€ðŸš€          1.00\n",
      "1              You NEED to see this about GME ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€          0.59\n",
      "2                     Short Squeeze Incoming ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€          0.93\n",
      "3  THIS CONVINCED ME TO ALL IN ðŸ’°GME (EXTREME PUMP...          0.50\n",
      "4  You already know what we must do brothers and ...          0.97\n",
      "Data saved to 'final_reddit_data.csv'.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 250 entries, 60083 to 1082710\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   title         250 non-null    object \n",
      " 1   upvote_ratio  250 non-null    float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 5.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Ensure the folder exists\n",
    "if not os.path.exists(root_folder):\n",
    "    print(f\"Error: Folder '{root_folder}' not found!\")\n",
    "    exit()\n",
    "\n",
    "# List to store the extracted rows\n",
    "data_rows = []\n",
    "\n",
    "# Iterate over subfolders inside redditFinance\n",
    "for subfolder in os.listdir(root_folder):\n",
    "    subfolder_path = os.path.join(root_folder, subfolder)\n",
    "    \n",
    "    if os.path.isdir(subfolder_path):  # Ensure it's a directory\n",
    "        for file in os.listdir(subfolder_path):\n",
    "            if file.endswith(\".csv\"):  # Process only CSV files\n",
    "                file_path = os.path.join(subfolder_path, file)\n",
    "\n",
    "                try:\n",
    "                    # Read CSV and only select \"title\" and \"upvote_ratio\" columns if available\n",
    "                    df = pd.read_csv(file_path, usecols=[\"title\", \"upvote_ratio\"])\n",
    "\n",
    "                    # Append extracted data to the list\n",
    "                    data_rows.append(df)\n",
    "\n",
    "                    print(f\"Processed {file_path}\")\n",
    "\n",
    "                except ValueError:  # Handle cases where columns are missing\n",
    "                    print(f\"Skipping {file_path}: Required columns not found.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "# Combine all extracted data into a single DataFrame\n",
    "if data_rows:\n",
    "    combined_df = pd.concat(data_rows, ignore_index=True)\n",
    "    print(f\"\\nFinal DataFrame with {len(combined_df)} rows:\")\n",
    "    print(combined_df.head())\n",
    "\n",
    "    # Randomly select 250 rows\n",
    "    sampled_reddit_df = combined_df.sample(n=250, random_state=42)\n",
    "\n",
    "    # Save the sampled DataFrame to a CSV file\n",
    "    sampled_reddit_df.to_csv(os.path.join(os.getcwd(), \"../data/final_reddit_data.csv\"), index=False)\n",
    "    print(\"Data saved to 'final_reddit_data.csv'.\")\n",
    "\n",
    "    # Print information about the sampled DataFrame\n",
    "    print(sampled_reddit_df.info())\n",
    "    \n",
    "else:\n",
    "    print(\"No valid data found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
