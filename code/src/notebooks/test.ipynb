{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "\n",
    "\n",
    "# Load model directly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache_dir = \"./hf_cache\"\n",
    "# pipe = pipeline(\"text-generation\", model=\"openai-community/gpt2\", cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = \"./hf_cache\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\", cache_dir=cache_dir)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\", cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ( \"Customer Profile: User with a Low risk appetite, interested in Education, Investing, Real Estate, focused on financial goals like Home Loan Repayment, Study Abroad, and prefers Real Estate. Shows Anxious sentiment and spends mostly on Education, Kim-Vega, High. \\n\"\n",
    "            \"Available Products: product_id title ... type content_id 0 P001 Premium Travel Credit Card ... product NaN 1 P002 Basic Cashback Card ... product NaN 2 P003 Robo-Advisory Portfolio ... product NaN 3 P004 HNI Wealth Management ... product NaN 4 P005 Crypto Investment Assistant ... product NaN 5 P006 Senior Citizen FD Plan ... product NaN 6 P007 Startup Business Loan ... product NaN 7 P008 Gold Loan ... product NaN 8 P009 Student Education Loan ... product NaN 9 P010 Luxury Lifestyle Credit Card ... product NaN 10 P011 Kim-Vega Lifestyle Credit Card ... product NaN 11 NaN Beginner's Guide to Mutual Funds ... content C001 12 NaN Understanding Market Volatility ... content C002 13 NaN Top Tax Saving Instruments ... content C003 14 NaN Travel Hacking with Credit Cards ... content C004 15 NaN Crypto 101 ... content C005 16 NaN Retirement Planning at 30 ... content C006 17 NaN Luxury Travel on Points ... content C007 18 NaN Student Budgeting Tips ... content C008 19 NaN Wealth Tips for HNIs ... content C009 20 NaN Safe Investment Options ... content C010\"\n",
    "            \"From the list above, recommend the top 3 most relevant financial products for the customer.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[44939, 13118,    25, 11787,   351,   257,  7754,  2526, 20788,    11,\n",
       "          4609,   287,  7868,    11,  7488,   278,    11,  6416, 23015,    11,\n",
       "          5670,   319,  3176,  4661,   588,  5995, 32314,  1432,   323,   434,\n",
       "            11, 12481,  2275,  6344,    11,   290, 26237,  6416, 23015,    13,\n",
       "         25156,  1052, 48392, 15598,   290, 16887,  4632,   319,  7868,    11,\n",
       "          6502,    12,    53, 26470,    11,  3334,    13,   220,   198, 10493,\n",
       "         18675,    25,  1720,    62,   312,  3670,  2644,  2099,  2695,    62,\n",
       "           312,   657,   350,  8298, 17315, 13524, 10504,  5172,  2644,  1720,\n",
       "         11013,    45,   352,   350, 21601, 14392, 16210,  1891,  5172,  2644,\n",
       "          1720, 11013,    45,   362,   350, 11245, 39702,    12,  2782, 41783,\n",
       "          4347, 13652,  2644,  1720, 11013,    45,   513,   350, 22914,   367,\n",
       "         22125, 35151,  8549,  2644,  1720, 11013,    45,   604,   350, 22544,\n",
       "         36579, 20877, 15286,  2644,  1720, 11013,    45,   642,   350, 28041,\n",
       "         14017, 22307, 30002,  5224,  2644,  1720, 11013,    45,   718,   350,\n",
       "         25816, 40472,  7320, 32314,  2644,  1720, 11013,    45,   767,   350,\n",
       "         25257,  3561, 32314,  2644,  1720, 11013,    45,   807,   350, 28694,\n",
       "         13613,  7868, 32314,  2644,  1720, 11013,    45,   860,   350, 20943,\n",
       "         17145,  1601,   406, 42004, 10504,  5172,  2644,  1720, 11013,    45,\n",
       "           838,   350, 28555,  6502,    12,    53, 26470,   406, 42004, 10504,\n",
       "          5172,  2644,  1720, 11013,    45,  1367, 11013,    45, 16623,  1008,\n",
       "           338, 10005,   284, 48807, 34068,  2644,  2695,   327,  8298,  1105,\n",
       "         11013,    45, 28491,  5991,  4709, 18486,  2644,  2695,   327, 21601,\n",
       "          1511, 11013,    45,  5849,  9241, 34689, 43953,  2644,  2695,   327,\n",
       "         11245,  1478, 11013,    45, 13524,   367,  5430,   351, 10504, 15824,\n",
       "          2644,  2695,   327, 22914,  1315, 11013,    45, 36579,  8949,  2644,\n",
       "          2695,   327, 22544,  1467, 11013,    45, 41863, 21913,   379,  1542,\n",
       "          2644,  2695,   327, 28041,  1596, 11013,    45, 17145,  1601, 13524,\n",
       "           319, 11045,  2644,  2695,   327, 25816,  1248, 11013,    45, 13613,\n",
       "         15401,   278, 27558,  2644,  2695,   327, 25257,   678, 11013,    45,\n",
       "         35151, 27558,   329,   367,    45,  3792,  2644,  2695,   327, 28694,\n",
       "          1160, 11013,    45, 19978, 20877, 18634,  2644,  2695,   327, 20943,\n",
       "          4863,   262,  1351,  2029,    11,  4313,   262,  1353,   513,   749,\n",
       "          5981,  3176,  3186,   329,   262,  6491,    13]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[44939, 13118,    25, 11787,   351,   257,  7754,  2526, 20788,    11,\n",
       "          4609,   287,  7868,    11,  7488,   278,    11,  6416, 23015,    11,\n",
       "          5670,   319,  3176,  4661,   588,  5995, 32314,  1432,   323,   434,\n",
       "            11, 12481,  2275,  6344,    11,   290, 26237,  6416, 23015,    13,\n",
       "         25156,  1052, 48392, 15598,   290, 16887,  4632,   319,  7868,    11,\n",
       "          6502,    12,    53, 26470,    11,  3334,    13,   220,   198, 10493,\n",
       "         18675,    25,  1720,    62,   312,  3670,  2644,  2099,  2695,    62,\n",
       "           312,   657,   350,  8298, 17315, 13524, 10504,  5172,  2644,  1720,\n",
       "         11013,    45,   352,   350, 21601, 14392, 16210,  1891,  5172,  2644,\n",
       "          1720, 11013,    45,   362,   350, 11245, 39702,    12,  2782, 41783,\n",
       "          4347, 13652,  2644,  1720, 11013,    45,   513,   350, 22914,   367,\n",
       "         22125, 35151,  8549,  2644,  1720, 11013,    45,   604,   350, 22544,\n",
       "         36579, 20877, 15286,  2644,  1720, 11013,    45,   642,   350, 28041,\n",
       "         14017, 22307, 30002,  5224,  2644,  1720, 11013,    45,   718,   350,\n",
       "         25816, 40472,  7320, 32314,  2644,  1720, 11013,    45,   767,   350,\n",
       "         25257,  3561, 32314,  2644,  1720, 11013,    45,   807,   350, 28694,\n",
       "         13613,  7868, 32314,  2644,  1720, 11013,    45,   860,   350, 20943,\n",
       "         17145,  1601,   406, 42004, 10504,  5172,  2644,  1720, 11013,    45,\n",
       "           838,   350, 28555,  6502,    12,    53, 26470,   406, 42004, 10504,\n",
       "          5172,  2644,  1720, 11013,    45,  1367, 11013,    45, 16623,  1008,\n",
       "           338, 10005,   284, 48807, 34068,  2644,  2695,   327,  8298,  1105,\n",
       "         11013,    45, 28491,  5991,  4709, 18486,  2644,  2695,   327, 21601,\n",
       "          1511, 11013,    45,  5849,  9241, 34689, 43953,  2644,  2695,   327,\n",
       "         11245,  1478, 11013,    45, 13524,   367,  5430,   351, 10504, 15824,\n",
       "          2644,  2695,   327, 22914,  1315, 11013,    45, 36579,  8949,  2644,\n",
       "          2695,   327, 22544,  1467, 11013,    45, 41863, 21913,   379,  1542,\n",
       "          2644,  2695,   327, 28041,  1596, 11013,    45, 17145,  1601, 13524,\n",
       "           319, 11045,  2644,  2695,   327, 25816,  1248, 11013,    45, 13613,\n",
       "         15401,   278, 27558,  2644,  2695,   327, 25257,   678, 11013,    45,\n",
       "         35151, 27558,   329,   367,    45,  3792,  2644,  2695,   327, 28694,\n",
       "          1160, 11013,    45, 19978, 20877, 18634,  2644,  2695,   327, 20943,\n",
       "          4863,   262,  1351,  2029,    11,  4313,   262,  1353,   513,   749,\n",
       "          5981,  3176,  3186,   329,   262,  6491,    13,   198,   198,   464,\n",
       "          1708,  3186,   389,   407,  1695,   329,  5001,   319,   428,  2524,\n",
       "            13,   198,   198,   464,  1708,  3186,   389]])\n",
       "torch.Size([1, 347])\n",
       "Customer Profile: User with a Low risk appetite, interested in Education, Investing, Real Estate, focused on financial goals like Home Loan Repayment, Study Abroad, and prefers Real Estate. Shows Anxious sentiment and spends mostly on Education, Kim-Vega, High. \n",
       "Available Products: product_id title ... type content_id 0 P001 Premium Travel Credit Card ... product NaN 1 P002 Basic Cashback Card ... product NaN 2 P003 Robo-Advisory Portfolio ... product NaN 3 P004 HNI Wealth Management ... product NaN 4 P005 Crypto Investment Assistant ... product NaN 5 P006 Senior Citizen FD Plan ... product NaN 6 P007 Startup Business Loan ... product NaN 7 P008 Gold Loan ... product NaN 8 P009 Student Education Loan ... product NaN 9 P010 Luxury Lifestyle Credit Card ... product NaN 10 P011 Kim-Vega Lifestyle Credit Card ... product NaN 11 NaN Beginner's Guide to Mutual Funds ... content C001 12 NaN Understanding Market Volatility ... content C002 13 NaN Top Tax Saving Instruments ... content C003 14 NaN Travel Hacking with Credit Cards ... content C004 15 NaN Crypto 101 ... content C005 16 NaN Retirement Planning at 30 ... content C006 17 NaN Luxury Travel on Points ... content C007 18 NaN Student Budgeting Tips ... content C008 19 NaN Wealth Tips for HNIs ... content C009 20 NaN Safe Investment Options ... content C010From the list above, recommend the top 3 most relevant financial products for the customer.\n",
       "\n",
       "The following products are not available for purchase on this site.\n",
       "\n",
       "The following products are\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outputs = model.generate(**inputs)\n",
    "print(outputs)\n",
    "print(outputs.shape)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations_text = tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
